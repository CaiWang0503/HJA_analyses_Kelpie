#!/bin/bash
#SBATCH -p gpu # -p for 'partition name'
     # gpu 24 hrs default, 7 d max, 2 GPUs max, 192GB per GPU
#SBATCH --qos=gpu # QOS to be allowed to use GPU servers
#SBATCH --gres=gpu:2 # Number of GPUs (per node)  # gpu:1 is the default. if I set gpu:1, but i use n_gpu=2 in sjsdm_cv() code, sjsdm_cv() will grab 2 gpus, including from jobs by other users
#SBATCH --mem 128G #
#SBATCH --ntasks=2 # number of slots == number of CPU cores (match n_cpu)
#SBATCH -t 48:00:00 # 48 hrs # time (DD-HH:MM)
#SBATCH --job-name=sjsdmcvg # job name
#SBATCH -o sjsdmcvg.out
#SBATCH -e sjsdmcvg.err
#SBATCH --mail-user=dougwyu@mac.com #sends email to me
#SBATCH --mail-type=ALL           #Mail events (NONE, BEGIN, END, FAIL, ALL)

# ran on 20200830 on ada gpu, 17.5 hrs to complete 274 spp, 87 sites, gismslidar, loocv for each dataset (qp, pa)
# sbatch sjsdm_gpu_20200909.sub # to submit the job

module purge
# source /gpfs/home/b042/scratch/sjSDM_env/bin/activate # activate sjSDM environment to make pytorch available
module add R

# upload sjsdm_gpu_20200909.sub and sjsdm_gpu_20200909.R into working folder (~/sjSDM)
Rscript --vanilla sjsdm_cv_gpu_20200909.R
