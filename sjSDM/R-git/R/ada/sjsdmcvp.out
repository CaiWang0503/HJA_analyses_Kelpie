> Sys.setenv(RETICULATE_PYTHON="/gpfs/scratch/b042/sjSDM_env/bin/python")
> 
> # # arguments
> # args <- commandArgs(trailingOnly = TRUE) # if you want to pass arguments to R from the shell (bash) command line
> # print(args)
> # # test if there is at least one argument: if not, return an error
> # if (length(args) < 3) {
> #   stop("At least three arguments must be supplied", call.=FALSE)
> # }
> # 
> 
> # packages
> library(sjSDM)
> library(here)
> library(tidyverse)
> library(fs)
> library(glue)
> 
> # set variables
> rundate <- 20201030 # run date
> minocc <- 5 # minimum occupancy (incidence) per OTU
> envvar <- "gismslidar" # gismslidarmin, gismslidar, gis, ms, lidar, mslidar
> 
> abund <- "pa" # pa is 0/1 data, qp is quasiprob data
> # chk sjsdm_cv() code to see if have chosen DNN to fit the env covariates
> 
> resultsfolder <- glue("results_{rundate}_{minocc}minocc_{envvar}_{abund}_loocv")
> dir_create(resultsfolder) # create results/ directory, but only if the results/ directory does not already exist
> datafolder <- glue("data_{rundate}_{minocc}minocc_{envvar}")
>   # paste0 alternative syntax
>   # datafolder <- paste0("data_", rundate, "_", minocc, "minocc_", envvar)
> 
> # read in data
> # env data:  scale.env, should be scaled
> scale.env <- read_csv(here(datafolder, "scale.env.csv"))
> 
> # species data: otu.pa.csv, otu.qp.csv, qp == quasiprob, pa == 0/1
> # check value of abund for qp or pa data
> otu.data <- read_csv(here(datafolder, glue("otu.{abund}.csv")))
> 
> # XY data: XY.csv, should be scaled
> XY <- read_csv(here(datafolder, "XY.csv"))
> 
> # sjSDM_cv
> tune_results = sjSDM_cv(
+   Y = as.matrix(otu.data),
+   env = linear(as.matrix(scale.env)),
+   # env = DNN(as.matrix(scale.env)),
+   spatial = linear(XY, ~0 + UTM_E:UTM_N),
+   biotic = bioticStruct(on_diag = FALSE, inverse = FALSE), # inverse=TRUE is 'better' but much slower
+   tune = "random", # random steps in tune-parameter space
+   learning_rate = 0.003, # 0.01 default, 0.003 recommended for high species number
+   family = stats::binomial("probit"), # for both p/a and quasiprob data, default
+   CV = nrow(as.matrix(otu.data)), # 5L for 5-fold cross validation, nrow(as.matrix(otu.data)) for LOOCV
+   tune_steps = 60L, # 20L is default
+   alpha_cov = seq(0, 1, 0.1),
+   alpha_coef = seq(0, 1, 0.1),
+   lambda_cov = seq(0, 0.1, 0.001), 
+   lambda_coef = seq(0, 0.1, 0.001),
+   n_cores = 2L, # NULL, # or 10L for small models, run this many sjsdm models at once (1 per CPU core). 10L is too much for large models because the 10 CPUs try to run on only the 2 GPUs available on ada: 5/GPU
+   n_gpu = 2L,# spread over this many GPU cards
+   iter = 150L, # 2L
+   sampling = 5000L # default is 5000L
+   )
