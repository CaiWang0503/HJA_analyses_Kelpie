---
---

```{r setup}
lapply(c("ggplot2", "gridExtra",'vegan', 'labdsv', 'tidyverse', 'scatterplot3d', 'gridBase', 'grid', 'ggcorrplot','here', 'rescale'), library, character.only=T)

lapply(c('reticulate','sjSDM'), library, character.only=T)
	
here::here()
getwd()
source(here("R", "source", "sjsdm_function.r"))
```

```{r convert data (go directly to 'load files')}
# for backup, converted data are saved

# format OTU data, combine with lidar data 
#dy not lidar data. it's landsat data.  there will be lidar data later, so must name it correctly
# (remote sensing data)
mulspec.env = read.csv(here('..','..','HJA_scripts','10_eo_data','biodiversity_site_info_multispectral_2020-04-13.txt'), header=T, sep=',', stringsAsFactors = F, na.strings='NA')
str(mulspec.env)
	
# ('HJA_analyses_Kelpie/Kelpie_maps' folder) 
otu.env1.noS = read.csv(here('..','..','Kelpie_maps', 'outputs_minimap2_20200221_F2308_f0x2_q48_kelpie20200214_vsearch97','sample_by_species_table_F2308_minimap2_20200221_kelpie20200214.csv'), header=T, sep=',', stringsAsFactors = F, na.strings='NA')
	
otu.env1.spike = read.csv(here('..','..','Kelpie_maps', 'outputs_minimap2_20200221_F2308_f0x2_q48_kelpie20200214_vsearch97', 'sample_by_species_corr_table_F2308_minimap2_20200221_kelpie20200214.csv'), header=T, sep=',', stringsAsFactors = F, na.strings='NA')
	
print(c(dim(otu.env1.spike), dim(otu.env1.noS)))
# 1173-26, more otus
	
names(otu.env1.noS)[1:26] == names(otu.env1.spike)[1:26]
	
names(otu.env1.noS)[1:26]=c('SiteName', 'UTM_E','UTM_N','old.growth.str', 'yrs.disturb','point.ID','poly.ID','AGENCY','unit.log', 'name.log','log.yr','yrs.log.2018','log.treat','yrs.disturb.level', 'elevation','canopy.ht','min.T','max.T', 'precipitation','metre.road', 'metre.stream', 'yrs.disturb.min','hja','trap','session','site_trap_period')
names(otu.env1.spike)[1:26]=names(otu.env1.noS)[1:26]
	
str(otu.env1.spike[,1:27])
	

# ........ format mulspec.env .......
sort(mulspec.env$SiteName) == sort(unique(otu.env1.spike$SiteName))
	
#NDVI - normalized difference vegetation index (calculated using bands 4 and 5): NDVI = (NearIR-Red)/(NearIR+Red)
#       these values should range between -1 and 1. Values in these columns should be divided by 1000
#EVI - enhanced vegetation index (calculated using bands 4, 5, and 2):  2.5 * ((Band 5 – Band 4) / (Band 5 + 6 * Band 4 – 7.5 * Band 2 + 1))
#      the values in these columns should be divided by 1000
names(mulspec.env)   #sort()
# 4 NDVI, 4 EVI

#DY this line doesn't work. 
data.frame(mulspec.env$nor.NDVI_20180717, mulspec.env$EVI_20180818)
	
a = mulspec.env %>% select(13,14,27,28,41,42,55,56) %>% rename(nor.NDVI_20180717=1, nor.EVI_20180717=2, nor.NDVI_20180726=3, nor.EVI_20180726=4, nor.NDVI_20180802=5, nor.EVI_20180802=6, nor.NDVI_20180818=7, nor.EVI_20180818=8)/1000
	
a[,c(1,3,5,7)]
# mean of all 4 NDVI, EVI
mulspec.env= cbind(mulspec.env,a)
str(mulspec.env)
	
mulspec.env$mean.NDVI = base::rowMeans(mulspec.env[,c(60,62,64,66)])
mulspec.env$mean.EVI = base::rowMeans(mulspec.env[,c(61,63,65,67)])
mulspec.env[,c(60,62,64,66,68)]
mulspec.env[,c(61,63,65,67,69)]
	

# ... explore OTU reads ...
names(otu.env1.spike)[1:27]
	
hist(otu.env1.spike[,30])
sort(unique(otu.env1.noS[,30]))
	
which(is.na(otu.env1.noS[,28]))#:dim(otu.env1.noS)[2]
which(is.na(otu.env1.noS[,29]))
# 181 237
	
table(is.na(otu.env1.noS[c(181,237),27:1173]))
	
table(is.na(otu.env1.spike[c(181,237),27:1173]))
	
otu.env1.noS$SiteName[c(181,237)]
	
# delete row 181, 237 -> "HOBO-040", "290415" 
dim(otu.env1.noS)
	
otu.env1.noS = otu.env1.noS[-c(181,237),]
	
dim(otu.env1.spike)
	
otu.env1.spike = otu.env1.spike[-c(181,237),]
	

# ....... scale variables .......
a = select(otu.env1.spike,15:22)%>%rename(elevation.scale=1,canopy.ht.scale=2,min.T.scale=3, max.T.scale=4, precipitation.scale=5, metre.road.scale=6, metre.stream.scale=7, yrs.disturb.min.scale=8)%>% scale()
	
otu.env1.spike = cbind(otu.env1.spike[,1:26], data.frame(a), otu.env1.spike[,27:dim(otu.env1.spike)[2]])
dim(otu.env1.spike)
	
otu.env1.noS = dplyr::left_join(otu.env1.noS, otu.env1.spike[,26:34], by=c('site_trap_period', 'site_trap_period'), copy=F)
otu.env1.noS = otu.env1.noS[,c(1:26,1174:1181,27:1173)]
str(otu.env1.noS[,1:34])
	

# ..... combine lidar .....
str(mulspec.env)
	
hist(mulspec.env$mean.NDVI)
hist(mulspec.env$mean.EVI)
	
a = select(mulspec.env,68:69) %>% rename(mean.NDVI.scale=1,mean.EVI.scale=2) %>% scale()
mulspec.env = cbind(mulspec.env,data.frame(a))
	
hist(mulspec.env$mean.NDVI.scale)
hist(mulspec.env$mean.EVI.scale)
	
# row 181, 237 -> "HOBO-040", "290415" in OTU datasets
mulspec.env$SiteName == sort(unique(otu.env1.noS$SiteName))
	
otu.env1.spike = dplyr::left_join(otu.env1.spike, mulspec.env[,c(1,70:71)], by=c('SiteName', 'SiteName'), copy=F) 
str(otu.env1.spike[,1:37])
	
otu.env1.spike = otu.env1.spike[,c(1:34,1182:1183,35:1181)]
dim(otu.env1.spike)
	
otu.env1.noS = dplyr::left_join(otu.env1.noS, mulspec.env[,c(1,70:71)], by=c('SiteName', 'SiteName'), copy=F) 
str(otu.env1.noS[,1:37])
	
otu.env1.noS = otu.env1.noS[,c(1:34,1182:1183,35:1181)]
dim(otu.env1.noS)
	
# write.table(otu.env1.noS, here('kelpie','formatted_data','mulspec_sample_by_species_table_F2308_minimap2_20200221_kelpie20200214.csv'), row.names=F, sep=',')
# 	
# write.table(otu.env1.spike, here('kelpie','formatted_data','mulspec_sample_by_species_corr_table_F2308_minimap2_20200221_kelpie20200214.csv'), row.names=F, sep=',')
# 	
# write.table(mulspec.env, here('kelpie','rs_data','sjsdm_biodiversity_site_info_multispectral_2020-04-13.csv'), row.names= F, sep=',')
	
```

```{r convert data2 (go directly to 'load files')}
# for backup, data are already saved
# convert to present/rel.abun according to formatted data 
# ( continue with 'convert data')

# (remote sensing data, load data formatted for sjsdm)
mulspec.env = read.csv(here('kelpie','rs_data','sjsdm_biodiversity_site_info_multispectral_2020-04-13.csv'), header=T, sep=',', stringsAsFactors = F, na.strings='NA')
str(mulspec.env)
	
# ('formatted_data' folder, load data formatted for sjsdm) 
otu.env1.noS = read.csv(here('kelpie','formatted_data','mulspec_sample_by_species_table_F2308_minimap2_20200221_kelpie20200214.csv'), header=T, sep=',', stringsAsFactors = F, na.strings='NA')
	
otu.env1.spike = read.csv(here('kelpie','formatted_data','mulspec_sample_by_species_corr_table_F2308_minimap2_20200221_kelpie20200214.csv'), header=T, sep=',', stringsAsFactors = F, na.strings='NA')
	
print(c(dim(otu.env1.spike), dim(otu.env1.noS)))

	
# ..... convert to presence/absence .....
# . no spike
names(otu.env1.noS)[1:37]
	
#DY referring to columns by number is not robust because the number of environmental columns can change. it is always better to refer to columns by name. difficult to do this in the base R but it's easy to do this in tidyverse code
a = data.frame(lapply(data.frame(otu.env1.noS[,-c(1:36)]>0), as.numeric))
otu.env1.noS.present = cbind(otu.env1.noS[,1:36], a)

#DY old code using base::scale()
# a = data.frame(sapply(otu.env1.noS[,-c(1:36)],function(x) scale(x,center=F)))
# otu.env1.noS.rel.abun = cbind(otu.env1.noS[,1:36], a)

#DY rescaling to quasi-probabilities, following Max's advice
a = data.frame(sapply(otu.env1.noS[,-c(1:36)],function(x) scales::rescale(log(x+0.001))))
otu.env1.noS.rel.abun = cbind(otu.env1.noS[,1:36], a)
	

# . spike
a = data.frame(lapply(data.frame(otu.env1.spike[,-c(1:36)]>0), as.numeric))
otu.env1.spike.present = cbind(otu.env1.spike[,1:36], a)
# hist(otu.env1.spike$R200_218__Insecta_Diptera_Syrphidae_Blera_Blera_scitula_BOLD_ABY7981_size.595)

#DY old code using base::scale()
# a = data.frame(sapply(otu.env1.spike[,-c(1:36)], function(x) scale(x,center=F)))
# otu.env1.spike.rel.abun = cbind(otu.env1.spike[,1:36], a)

#DY rescaling to quasi-probabilities, following Max's advice
a = data.frame(sapply(otu.env1.spike[,-c(1:36)], function(x) scales::rescale(log(x+0.001))))
otu.env1.spike.rel.abun = cbind(otu.env1.spike[,1:36], a)

range(otu.env1.spike.rel.abun[,-c(1:36)])

#DY i usually comment out write.table() commands, to prevent running them incorrectly (e.g. when debugging)
# write.table(otu.env1.noS.rel.abun, here('kelpie','formatted_data','relAbun_mulspec_sample_by_species_table_F2308_minimap2_20200221_kelpie20200214.csv'), row.names=F, sep=',')
# write.table(otu.env1.noS.present, here('kelpie','formatted_data','present_mulspec_sample_by_species_table_F2308_minimap2_20200221_kelpie20200214.csv'), row.names=F, sep=',')
# 
# write.table(otu.env1.spike.present, here('kelpie','formatted_data','present_mulspec_sample_by_species_corr_table_F2308_minimap2_20200221_kelpie20200214.csv'), row.names=F, sep=',')
# write.table(otu.env1.spike.rel.abun, here('kelpie','formatted_data','relAbun_mulspec_sample_by_species_corr_table_F2308_minimap2_20200221_kelpie20200214.csv'), row.names=F, sep=',')
```


```{r load files, echo=FALSE}
# kelpie, remote sensing data 
mulspec.env = read.csv(here('kelpie','rs_data','sjsdm_biodiversity_site_info_multispectral_2020-04-13.csv'), header=T, sep=',', stringsAsFactors = F, na.strings='NA')
str(mulspec.env)

# ('formatted_data' folder, load data formatted for sjsdm, present) 
otu.env1.noS.present = read.csv(here('kelpie','formatted_data','present_mulspec_sample_by_species_table_F2308_minimap2_20200221_kelpie20200214.csv'), header=T, sep=',', stringsAsFactors = F, na.strings='NA')

#DY changed from lidar to mulspec in filename
otu.env1.noS.rel.abun = read.csv(here('kelpie','formatted_data','relAbun_mulspec_sample_by_species_table_F2308_minimap2_20200221_kelpie20200214.csv'), header=T, sep=',', stringsAsFactors = F, na.strings='NA')

otu.env1.spike.present = read.csv(here('kelpie','formatted_data','present_mulspec_sample_by_species_corr_table_F2308_minimap2_20200221_kelpie20200214.csv'), header=T, sep=',', stringsAsFactors = F, na.strings='NA')
	
otu.env1.spike.rel.abun = read.csv(here('kelpie','formatted_data','relAbun_mulspec_sample_by_species_corr_table_F2308_minimap2_20200221_kelpie20200214.csv'), header=T, sep=',', stringsAsFactors = F, na.strings='NA')
```

```{r explore remote sensing data }
#DY i comment out pdf() and dev.off() commands for the same reason: to prevent saving a file for no reason
# pdf(here('R','graph','describe_EVI_NDVI.pdf'), height=5, width=5)
	
range(mulspec.env[,60:67])
plot(1:96, mulspec.env[,61],ylim=c(0,3.3),type='l', main='solid - EVI, dash - NDVI')
lines(1:96, mulspec.env[,63], col='red')
lines(1:96, mulspec.env[,65], col='blue')
lines(1:96, mulspec.env[,67], col='green')
	
lines(1:96, mulspec.env[,60], lty=2, col='black')
lines(1:96, mulspec.env[,62], lty=2, col='red')
lines(1:96, mulspec.env[,64], lty=2, col='blue')
lines(1:96, mulspec.env[,66], lty=2, col='green')
	
# dev.off()
	
```

```{r subsets of data}
dataI.1.spike.present = subset(otu.env1.spike.present, session == 'S1' & trap == 'M1' )
#dataI.2.spike = subset(otu.env1.spike, session == 'S1' & trap == 'M2' )
	
dataI.1.spike.rel.abun = subset(otu.env1.spike.rel.abun, session == 'S1' & trap == 'M1' )
#dataII.2.spike = subset(otu.env1.spike, session == 'S2' & trap == 'M2' )
print(c(dim(dataI.1.spike.rel.abun), dim(dataI.1.spike.present)))
	
# .... if there's all zero OTUs ....
b = data.frame(otu=colnames(dataI.1.spike.rel.abun[,-c(1:36)]), zero=apply(dataI.1.spike.rel.abun[,-c(1:36)],2,sum)==0)
b$otu=as.character(b$otu)
dim(b)
	
dataI.1.spike.rel.abun2 = dplyr::select(dataI.1.spike.rel.abun, 1:36,b$otu[b$zero==F])
dim(dataI.1.spike.rel.abun2)
dataI.1.spike.rel.abun2[1:5,34:40]
	
b = data.frame(otu=colnames(dataI.1.spike.present[,-c(1:36)]), zero=apply(dataI.1.spike.present[,-c(1:36)],2,sum)==0)
b$otu=as.character(b$otu)
dim(b)
	
dataI.1.spike.present2 = dplyr::select(dataI.1.spike.present, 1:36,b$otu[b$zero==F])
dim(dataI.1.spike.present2)
dataI.1.spike.present2[1:5,34:40]
	
```

```{r sjsdm-model (rel.abun & 0/1)}
# models are already saved. go directly to 'model-analyse'

# according to nmds, precipitation, elevation, yrs.disturb.min, old.growth.str, T, canopy.height can be used for now

# ... session 1, Malaise I, spike, rel.abun ...
lrs = seq(-18, -1, length.out = 7);f = function(x) 2^x;lrs = f(lrs)
result = vector("list", 7)
	
scale.env = dataI.1.spike.rel.abun2[,c(1:3,24:36)]
str(scale.env)
	
for(i in 1:7) { 
model = sjSDM(X = scale.env, 
               Y = as.matrix(dataI.1.spike.rel.abun2[,-c(1:36)]),
               formula = ~ elevation.scale+canopy.ht.scale+min.T.scale+max.T.scale+precipitation.scale+metre.road.scale+metre.stream.scale+yrs.disturb.min.scale,  
               learning_rate = 0.01, 
               iter = 100L,
               step_size = 27L, l1_coefs = 0.07*lrs[i], l2_coefs = 0.03*lrs[i], # should be normally tuned...
               sampling = 100L,l1_cov = lrs[i], l2_cov = lrs[i])
  loss=unlist(model$logLik)
  history=model$history
  weights = list(beta = coef(model), sigma = getCov(model),loss=loss,history=history)
  rm(model)
  result[[i]] = weights
 }
  #iter = 1000L, step_size = 6L, sampling = 100L, learning_rate = 0.0003
  saveRDS(result, file = here('R','result','s-jSDM_result_s1_m1_spike.relAbun.RDS') )
  
# ... session 1, Malaise I, spike, rel.abun ...
lrs = seq(-18, -1, length.out = 7);f = function(x) 2^x;lrs = f(lrs)
result = vector("list", 7)
	
scale.env = dataI.1.spike.rel.abun2[,c(1:3,24:36)]
str(scale.env)
	
for(i in 1:7) { 
model = sjSDM(X = scale.env, 
               Y = as.matrix(dataI.1.spike.rel.abun2[,-c(1:36)]),
               formula = ~ elevation.scale+min.T.scale+max.T.scale+precipitation.scale+mean.NDVI.scale+mean.EVI.scale,  
               learning_rate = 0.01, 
               iter = 100L,
               step_size = 27L, l1_coefs = 0.07*lrs[i], l2_coefs = 0.03*lrs[i], # should be normally tuned...
               sampling = 100L,l1_cov = lrs[i], l2_cov = lrs[i])
  loss=unlist(model$logLik)
  history=model$history
  weights = list(beta = coef(model), sigma = getCov(model),loss=loss,history=history)
  rm(model)
  result[[i]] = weights
 }
  #iter = 1000L, step_size = 6L, sampling = 100L, learning_rate = 0.0003
  saveRDS(result, file = here('R','result','s-jSDM_result_s1_m1_spike.relAbun_lidar.RDS') )
	
```

```{r sjsdm-analyse-correlation (rel.abun)}
# s1, m1, spiked data 
# formula = ~ elevation.scale+canopy.ht.scale+min.T.scale+max.T.scale+precipitation.scale+metre.road.scale+metre.stream.scale+yrs.disturb.min.scale,  
result<-readRDS(here('R','result','s-jSDM_result_s1_m1_spike.relAbun.RDS'))
str(result)
	
lrs = seq(-18, -1, length.out = 7);f = function(x) 2^x;lrs = f(lrs)

  
# ... look at the loss
result[[1]]$loss
	
loss.all<-data.frame(LogLik = sapply(result, function(r) r$loss[1]))
loss.all$lrs<-lrsdataI.1.spike.rel.abun
str(loss.all)
	
loss.2 = data.frame(sapply(result, function(r) r$loss))
loss.2 = unlist(loss.2)
loss.2<-data.frame(LogLik = loss.2[seq(1,length(loss.2),by=2)], regulation=loss.2[seq(2,length(loss.2),by=2)])
data.frame(loss.2,loss.all$lrs)
	
pdf(here('R','graph','sjsdm_s1_m1_spike_relAbun','LogLikelihood.pdf'), height=5, width=5)
	
plot(x=loss.all$lrs,y=loss.all$LogLik,ylab = "LogLik",xlab = "lrs")
	
dev.off()
	

# . cov <- result$sigma 
dim(result[[5]]$sigma)
# [1] 850 850
co.env.spp <- cov2cor(result[[4]]$sigma)
spp.names<-colnames(dataI.1.spike.rel.abun2[,-c(1:36)])
rownames(co.env.spp)<-spp.names
colnames(co.env.spp)<-spp.names
	
rownames(co.env.spp) <- 1:850
colnames(co.env.spp) <- 1:850
	
ggcorrplot(co.env.spp[1:400,1:400], hc.order = T, outline.color = "white", insig = "blank",sig.level = 0.05, lab_size = 1,show.legend=T)
ggcorrplot(co.env.spp, hc.order = T, outline.color = "white", insig = "blank",sig.level = 0.05, lab_size = 1,show.legend=T)
	
overall = apply(abind::abind(lapply(result, function(r) cov2cor(r$sigma)), along = 0L), 2:3, sum)
	
# sum of all models with diff lrs
pdf(here('R','graph','sjsdm_s1_m1_spike_relAbun','7lrs_spp_corr.pdf'), height=20, width=20)
	
ggcorrplot(cov2cor(overall), hc.order = TRUE, outline.color = "white", insig = "blank",sig.level = 0.05, lab_size = 1,title=paste('lrs ',formatC(lrs[1],format='e',3),' to ',lrs[7],', sum of 7 models',sep=''))  
	
dev.off()
	
# .... heatmap
co.env.spp4<-cov2cor(result[[4]]$sigma)
range(co.env.spp4)
co.env.spp1<-cov2cor(result[[1]]$sigma)
co.env.spp7<-cov2cor(result[[7]]$sigma)
	
pdf(here('R','graph','sjsdm_s1_m1_spike_relAbun','spp_corr_heatmap_3lrs.pdf'), height=5, width=15)
	
par(mfrow=c(1,3))
cols = (colorRampPalette(c("blue", "white", "red")))(10)
graphics::image(co.env.spp1[indices$rowInd, indices$rowInd], col = cols, main=paste('lrs ',formatC(lrs[1],format='e',3),sep=''),xaxt = "n", yaxt = "n", xlab=paste('spp corr ',round(min(co.env.spp1),4),' - ', max(co.env.spp1),sep=''), ylab='blue (min value) to red (max value)')
image(co.env.spp4[indices$rowInd, indices$rowInd], col = cols, main=paste('species correlation (850 spp), lrs ',formatC(lrs[4],format='e',3),sep=''),xaxt = "n", yaxt = "n", xlab=paste('spp corr ',round(min(co.env.spp4),4),' - ', max(co.env.spp4),sep=''))
image(co.env.spp7[indices$rowInd, indices$rowInd], col = cols, main=paste('lrs ',round(lrs[7],8),sep=''),xaxt = "n", yaxt = "n", xlab=paste('spp corr ',round(min(co.env.spp7),4),' - ', max(co.env.spp7),sep=''))
	
dev.off()
	

```

```{r model-analyse-polygon (rel.abun)}
# ..... Polygon Drawing .....
# . species association .
# result[1][4][7], lrs 
number=10
lr_step=7 # change here for different result list
sigma = re_scale(result[[lr_step]]$sigma)[order(apply(dataI.1.spike.rel.abun2[,-c(1:36)], 2, sum)), order(apply(dataI.1.spike.rel.abun2[,-c(1:36)], 2, sum))]

sigmas = sigma[base::upper.tri(sigma)]
upper = order(sigmas, decreasing = TRUE)[1:number]
lower = order(sigmas, decreasing = FALSE)[1:number]
cuts = cut(sigmas, breaks = seq(-1,1,length.out = 12))
summary(cuts)
	
to_plot = 1:length(sigmas) %in% upper | 1:length(sigmas) %in% lower
levels(cuts) = viridis::viridis(11)
cuts = as.character(cuts)
n = ncol(result[[lr_step]]$sigma)
lineSeq = 4.7
nseg = 100
	
pdf(paste(here('R','graph','sjsdm_s1_m1_spike_relAbun','spp_cov_lrs'),formatC(lrs[lr_step],format=NULL,3),'.pdf',sep=''), height=8, width=8)
	
plot(NULL, NULL, xlim = c(-5,5), ylim =c(-5,5),pty="s", axes = F, xlab = "", ylab = "")
text(x = 0, y = 5.7, pos = 3, xpd = NA, labels = paste("Penalty: ",formatC(lrs[lr_step],format=NULL,4),sep=''))
text(x = -6, y = 5.7, pos = 3, xpd = NA, labels = "A", font = 2, cex = 1.5)
	
xx = lineSeq*cos( seq(0,2*pi, length.out=nseg) )
yy = lineSeq*sin( seq(0,2*pi, length.out=nseg) )
polygon(xx,yy, col= "white", border = "black", lty = 1, lwd = 1)
angles = seq(0,355,length.out = n+1)[1:(n)]
xx = cos(deg2rad(angles))*lineSeq
yy = sin(deg2rad(angles))*lineSeq
	
counter = 1
coords = cbind(xx, yy, angles)
for(i in 2:n) {
	for(j in 1:(i-1)){
      if(to_plot[counter]) {
		print (c(i,j,counter))
		add_curve(coords[i,], coords[j,], col = cuts[counter], n = 5, lineSeq = lineSeq)
	}
	counter = counter + 1
  }
}
# ??? correlation plotted, why legend says 'covariance' 
	
OTU_log = log(sort(apply(dataI.1.spike.rel.abun2[, -c(1:36)], 2, sum)))
range(OTU_log)
OTU_log[1]=0 
cuts = cut(OTU_log, breaks = 10)
cols = viridis::magma(10) 
	
levels(cuts) = cols
sppnames2=paste("spp",1:20,sep = "")
abun=as.character(cuts)
sppsort=1:20
	
OTU_sort_abun <- data.frame(sppsort=rep(sppsort, len=dim(dataI.1.spike.rel.abun2[,-c(1:36)])[2]), sum = apply(dataI.1.spike.rel.abun2[,-c(1:36)], 2, sum))
OTU_sort_abun = OTU_sort_abun[order(OTU_sort_abun$sum), ]
OTU_sort_abun$abun<-abun
OTU_sort_abun = OTU_sort_abun[order(OTU_sort_abun$sppsort), ]
	
# .. add abundance legends
lineSeq = 5.0
for(i in 1:length(OTU_log)){
  p1 = coords[i,]
  x1 = c(cos(deg2rad(p1[3]))*(lineSeq+0.1), cos(deg2rad(p1[3]))*(lineSeq+0.3))
  y1 = c(sin(deg2rad(p1[3]))* (lineSeq+0.1), sin(deg2rad(p1[3]))* (lineSeq+0.3))
  segments(x0 = x1[1], x1 = x1[2], y0 = y1[1], y1 = y1[2], col = as.character(cuts[i]), lend = 1)
}
	
add_legend(viridis::viridis(11), angles = c(140,110),radius = 5.4)
text(cos(deg2rad(123))*(lineSeq+1), sin(deg2rad(123))*(lineSeq+1.2), labels = "covariance", pos = 2, xpd = NA)
	
add_legend(cols = cols, range = c(2, 850), angles = c(70,40),radius = 5.4)
text(cos(deg2rad(53))*(lineSeq+1), sin(deg2rad(55))*(lineSeq+1.1), labels = "low to high", pos = 4, xpd = NA) 
text(cos(deg2rad(64))*(lineSeq+1.3), sin(deg2rad(62))*(lineSeq+1.1), labels = "sum of rel. abun.", pos = 4, xpd = NA) 
	
### arrows
segments(x0 = cos(deg2rad(-1))*(lineSeq-0.2), x1 = cos(deg2rad(-1))*(lineSeq+0.9), y0 = sin(deg2rad(-1))*(lineSeq-0.2), y1 = sin(deg2rad(-1))*(lineSeq+0.9), xpd = NA)
segments(x0 = cos(deg2rad(356))*(lineSeq-0.2), x1 = cos(deg2rad(356))*(lineSeq+0.9), 
         y0 = sin(deg2rad(356))*(lineSeq-0.2), y1 = sin(deg2rad(356))*(lineSeq+0.9), xpd = NA)
	
# first
angles = seq(150,195,length.out = n+1)[1:(n)]
xx = cos(deg2rad(angles))*(lineSeq+0.6)
yy = sin(deg2rad(angles))*(lineSeq+0.6)
lines(xx, yy, xpd = NA)
end = curve_text(195+3, "Species",lineSeq = lineSeq+0.6,reverse = TRUE)
	
# second
angles = seq(rad2deg(end)+3,rad2deg(end)+45+8,length.out = n+1)[1:(n)]
xx = cos(deg2rad(angles))*(lineSeq+0.6)
yy = sin(deg2rad(angles))*(lineSeq+0.6)
lines(xx, yy, xpd = NA)
arrow_angle = max(angles)-2.8
polygon(x = c(cos(deg2rad(arrow_angle))*(lineSeq+0.5), cos(deg2rad(arrow_angle))*(lineSeq+0.7), cos(deg2rad(max(angles)))*(lineSeq+0.6), cos(deg2rad(arrow_angle))*(lineSeq+0.5)),
        y = c(sin(deg2rad(arrow_angle))*(lineSeq+0.5), sin(deg2rad(arrow_angle))*(lineSeq+0.7), sin(deg2rad(max(angles)))*(lineSeq+0.6), sin(deg2rad(arrow_angle))*(lineSeq+0.5)),col = "black", xpd = NA)
	
dev.off()
	
```

```{r model-analyse-polygon-envir (rel.abun)}
# ..... environmental effect .....
# Drawing parameter of OTU and environmental covariant
# result[1][4][7]
lr_step = 7 # change here for different result list
#formula = ~ elevation.scale+canopy.ht.scale+min.T.scale+max.T.scale+precipitation.scale+metre.road.scale+metre.stream.scale+yrs.disturb.min.scale,  
# 8 variables, excluding intercept
beta = as.matrix(result[[lr_step]]$beta[[1]])[2:9,]
effects= apply(beta, 1, function(o) sum(abs(o)))
	
turn_over = 1
n = ncol(result[[lr_step]]$sigma)# number of otus
max_effects= apply(beta ,2, function(e) which.max(abs(e)))
turn_over = 1
effect_comb = data.frame(cbind(max_effects,sapply(1:n, function(i) beta[max_effects[i],i] )))
# variables index & value which has biggest coefficient
	
sppname3=seq(1:20); sppname3=as.character(sppname3)
effect_comb$name <- rep(sppname3, len=850)
effect_comb$abun <- OTU_sort_abun$abun
effect_comb$abun<-as.character(effect_comb$abun)
effect_comb_ind = order(effect_comb[,1], effect_comb[,2])
effect_comb = effect_comb[effect_comb_ind,]
	
sigma = re_scale(result[[lr_step]]$sigma)[effect_comb_ind, effect_comb_ind]
sigmas = sigma[upper.tri(sigma)]
number=10
upper = order(sigmas, decreasing = TRUE)[1:number]
lower = order(sigmas, decreasing = FALSE)[1:number]
cuts = cut(sigmas, breaks = seq(-1,1,length.out = 12))
to_plot = 1:length(sigmas) %in% upper | 1:length(sigmas) %in% lower
levels(cuts) = viridis::viridis(11)
cuts = as.character(cuts)
n = ncol(result[[lr_step]]$sigma)
lineSeq = 3.5
nseg = 100
	
pdf(paste(here('R','graph','sjsdm_s1_m1_spike_relAbun','max_environ_lrs'),formatC(lrs[lr_step],format=NULL,3),'.pdf',sep=''), height=8, width=8)
	
#Drawing figure parameter
par( mar = c(1,2,2.1,2)+0.1)
plot(NULL, NULL, xlim = c(-5,5), ylim =c(-5,5),pty="s", axes = F, xlab = "", ylab = "")
text(x = -3.5, y = 5.3, pos = 3, xpd = NA, labels = paste("Penalty: ",formatC(lrs[lr_step],format=NULL,3), ', loss: ', formatC(loss.all[lr_step,1],7),sep=''), font = 2, cex = 1)
	
xx = lineSeq*cos( seq(0,2*pi, length.out=nseg) )
yy = lineSeq*sin( seq(0,2*pi, length.out=nseg) )
polygon(xx,yy, col= "white", border = "black", lty = 1, lwd = 1)
angles = seq(0,360,length.out = n+1)[1:(n)] # for all otus
xx = cos(deg2rad(angles))*lineSeq
yy = sin(deg2rad(angles))*lineSeq
	
##inside circle
counter = 1
coords = cbind(xx, yy, angles)
	
for(i in 2:n) {
  for(j in 1:(i-1)){
    
      if(to_plot[counter]) add_curve(coords[i,], coords[j,], col = cuts[counter], n = 5, species = T, lineSeq = 3.5, lwd = 1.3)
      counter = counter + 1
  }
}

lineSeq = 4.0
for(i in 1:n){
  p1 = coords[i,]
  x1 = c(cos(deg2rad(p1[3]))*(lineSeq+0.1), cos(deg2rad(p1[3]))*(lineSeq+0.3))
  y1 = c(sin(deg2rad(p1[3]))* (lineSeq+0.1), sin(deg2rad(p1[3]))* (lineSeq+0.3))
  segments(x0 = x1[1], x1 = x1[2], y0 = y1[1], y1 = y1[2], col = effect_comb$abun[i], lend = 1)
}
lineSeq = 3.5
	
##outside circle 
#formula = ~elevation.scale+canopy.ht.scale+min.T.scale+max.T.scale+precipitation.scale+metre.road.scale+metre.stream.scale+yrs.disturb.min.scale,  
evnames=c("ele","canopy","min.T","max.T","preci","road","stream","disturb")
colourCount = length(unique(evnames))
getPalette = colorRampPalette(RColorBrewer::brewer.pal(8, "Dark2"))
cols=getPalette(colourCount)

coords = data.frame(cbind(xx, yy, angles))
effect_comb=effect_comb[,-c(3,4)]
effect_comb2 = effect_comb
effect_comb2[,2] = ff(effect_comb[,2])
effect_comb2 = cbind(effect_comb2, effect_comb[,2])
effect_comb2 = data.frame(effect_comb2)
	
for(i in sort(unique(max_effects))) {
  sub<- coords %>% filter(effect_comb2$max_effects==i)
  sub_eff <- effect_comb2 %>% filter(max_effects==i)
  from <- sub[1,3]
  to <- sub[nrow(sub),3]

  x = c((3.6+1.5*(sub_eff[,2]))*cos(deg2rad(sub[,3]) ), 
        rev((3.6+1.5/2)*cos(deg2rad(sub[,3]))))
  
  y = c((3.6+1.5*(sub_eff[,2]))*sin(deg2rad(sub[,3])),
        rev((3.6+1.5/2)*sin(deg2rad(sub[,3]))))
  
  angleName = (from+to)/2
  if(angleName > 180) {reverse = TRUE} else {reverse = FALSE}
  ###environment variable text
  curve_text(angleName, label = evnames[i],reverse = reverse,lineSeq = 5.5, middle = TRUE, extend = 1.1, col = cols[i])
  ###environment variable bar
 if(i == 8) polygon(x-0.1, y, xpd = NA,col = cols[i])
#  else if(i == 5) polygon(x, y+0.55, xpd = NA,col = cols[i])
#  else if(i == 7) polygon(x-0.6, y-0.2, xpd = NA,col = cols[i])
#  else if(i == 9) polygon(x, y-0.55, xpd = NA,col = cols[i])
  #else if(i == 12) polygon(x-0.2, y-0.5, xpd = NA,col = cols[i])
 else 
polygon(x, y, xpd = NA,col = cols[i])
  
  
  ###environment variable range number
  text(srt = 0, 
         x = (3.6+1.5)*cos(deg2rad(sub[1,3]+4)), 
         y =  (3.6+1.5)*sin(deg2rad(sub[1,3]+4)), 
         xpd = NA, labels = round(min(sub_eff[,3]), 2), col = cols[i], cex = 0.8)
  
   text(srt = 0, 
         x = (3.6+1.5)*cos(deg2rad(sub[nrow(sub),3]-4)), 
         y =  (3.6+1.5)*sin(deg2rad(sub[nrow(sub),3]-4)), 
         xpd = NA, labels = round(max(sub_eff[,3]), 2), col = cols[i], cex = 0.8)
}
	
###legend of bar
rec_cols = viridis::viridis(11)
x = seq(3,5, length.out = 12)
for(i in 1:length(rec_cols)){
  rect(xleft = x[i], xright = x[i+1], ybottom = -5, ytop = -5+diff(x)[1], col = rec_cols[i], xpd = NA, border = NA)
}
text(x[1],-5.2, labels = -1)
text(x[11],-5.2, labels = +1)
	
#abun=as.character(abun)
abun1 = as.character(viridis::magma(10))
x = seq(-5.5,-3, length.out = 11)
for(i in 1:unique(length(abun))){
  rect(xleft = x[i], xright = x[i+1], ybottom = -5, ytop = -5+diff(x)[1], col = abun1[i], xpd = NA, border = NA)
  text(x= x[1]-0.2, y=-5.2, labels = "2", pos = 4, xpd = NA)
  text(x= x[10]-0.2, y=-5.2, labels = '850', pos = 4, xpd = NA)
}
text(x=-5.3, y=-5.3, labels = "rel. abun. spp.", pos = 4, xpd = NA)
	
dev.off()
	

```




