---
title: "assign_taxonomies"
author: "Douglas Yu"
date: "17/12/2019"
output: html_document
---

on macOS
download kelpie_${timestamp}_derep.fas from hpc

upload kelpie_${timestamp}_derep.fas to https://www.gbif.org/tools/sequence-id
download csv file, which will be called blastresult.csv
    There is probably a programmatic way to do this....

rename blastresult.csv to something memorable, e.g.  blastresult_GBIF_sequence_id_20200214.csv and save to HJA_scripts/5_taxonomy

```{r setup}
library(tidyverse)
library(seqinr)
library(conflicted)
  conflict_prefer("mutate", "dplyr", quiet = TRUE)
  conflict_prefer("select", "dplyr", quiet = TRUE)
  conflict_prefer("summarise", "dplyr", quiet = TRUE)
  conflict_prefer("filter", "dplyr", quiet = TRUE)
  conflict_prefer("first", "dplyr", quiet = TRUE)
  conflict_prefer("here", "here", quiet = TRUE)
  conflict_prefer("separate", "tidyr", quiet = TRUE)
  conflict_prefer("unite", "tidyr", quiet = TRUE)
```


```{r writeFasta function}
writeFasta <- function(data, filename){
  fastaLines = c()
  for (rowNum in 1:nrow(data)){
    fastaLines = c(fastaLines, as.character(paste(">", data[rowNum,"name"], sep = "")))
    fastaLines = c(fastaLines, as.character(data[rowNum,"seq"]))
  }
  fileConn <- file(filename)
  writeLines(fastaLines, fileConn)
  close(fileConn)
}
```


```{r import and reformat}
gbifresult <- "blastresult_GBIF_sequence_id_20200214"
gbifdf <- read_csv(paste0(gbifresult, ".csv"))
gbifdf <- gbifdf %>% 
    separate(occurrenceId, c("seqID", "OTUsize"), sep = ";", remove = FALSE) %>% 
    mutate(
        OTUsize = str_remove(OTUsize, "size=") # remove # "size=" from otusize column
    ) %>% 
    mutate(
        OTUsize = as.numeric(OTUsize)
    ) %>% 
    separate(classification, c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus", "Species"), sep = "_") %>% 
    arrange(desc(OTUsize))
```

Remove BLAST_NO_MATCH and non-Insecta, non-Arachnida
```{r filter}
gbifdf <- gbifdf %>% 
    filter(matchType != "BLAST_NO_MATCH") %>% 
    filter(Class %in% c("Insecta", "Arachnida"))
# 20200214:  5291 to 5221 seqs (70 seqs removed) 
```

Create consensusClassification following GBIF's recommendations on the website:
BLAST_EXACT_MATCH means species
BLAST_CLOSE_MATCH go to genus and add "sp" to consensusClassification
BLAST_WEAK_MATCH higher taxon (i keep only to order)
and add BOLDID to make it unique
```{r build consensus classification}
# str_replace_na() turns NA into literal "NA"s
gbifdf <- gbifdf %>% 
    mutate(
    consensusClassification = case_when(
        matchType == "BLAST_EXACT_MATCH" ~ str_c(str_replace_na(Class), str_replace_na(Order), str_replace_na(Family), str_replace_na(Genus), str_replace_na(Species), scientificName, sep = "_"),
        matchType == "BLAST_CLOSE_MATCH" ~ str_c(str_replace_na(Class), str_replace_na(Order), str_replace_na(Family), str_replace_na(Genus), "sp", scientificName, sep = "_"),
        matchType == "BLAST_WEAK_MATCH" ~ str_c(str_replace_na(Class), str_replace_na(Order), scientificName, sep = "_"),
        )
    ) %>% 
    select(occurrenceId, OTUsize, identity, consensusClassification, matchType, everything())
```


Next, I import into Geneious and align the sequences using Translation Align (MAFFT Alignment option, frame 2, invertebrate mitochondrial code). I then translated the alignment to amino acids to look for stop codons and to see the amino-acid alignment coloured for hydrophobicity (as a way of checkking for outlier sequences after translation)

1 sequence was very short, and i removed it. 
">R3997_19;size=1"
"AATAAATAATATAAGATTTTGATTACTA"

1 sequence was very long, had stop codons, and was not alignable (500 nts), and i removed it.
R3590_9;size=3

Four other sequences also had some stop codons (and low copy number).  However, after inspection, i can't see the indels, so i have kept them, although they are likely Numts. 
R1343_86;size=8
R904_134;size=5
R2320_84;size=2
R2352_82;size=1

Update: R1343_86 and R904_134 got mapped reads from multiple samples. The other two did not

```{r}
# from 5221 to 5219 sequences after Geneious filtering
gbifdf <- gbifdf %>% 
    filter(!(occurrenceId %in% c("R3997_19;size=1", "R3590_9;size=3")))
```


In previous runs through this pipeline, i have hand-corrected indels in some OTU sequences, which means that they need to have their taxonomies re-assigned. In that case, i upload to GBIF again, download the CSV file, and re-run the above script. In the 20200214 Kelpie run, I only deleted two OTU sequences, so i do not need to re-assign taxonomies, and i just run the next two chunks to remove the two deleted sequences from the gbifid file and create a new OTU sequence file.

Save the sequences as a fasta file
```{r}
kelpie_otus <- gbifdf %>% 
  unite(col = name1, seqID, consensusClassification, sep = "_") %>%
  mutate(
    name1 = str_c(name1, ";size=")
  ) %>% 
  unite(col = name, name1, OTUsize, sep = "") %>% 
  mutate(
    name = str_replace(name, "BOLD:", "BOLD_"),
    name = str_replace(name, " ", "_")
  ) %>% 
    select(name, seq = sequence)

# write to working directory
writeFasta(kelpie_otus, paste0("kelpie_20200214_BF3BR2_derep_filtered_geneious", ".fas"))
```


Cluster the sequences.  This is not a fully resolved problem because even with 97% and 96% clustering, there are still some size=1 OTUs that receive the same species ID as larger OTUs. I can use vsearch97_min2 (minsize = 2), which has 1,211 OTUs or vsearch96_min1, which has 1,171 OTUs, or vsearch96_min2, which has 1,149 OTUs. Not a huge amount of difference amongst them
```{bash}
# send to terminal:  cmd-alt-numeric_keypad_enter
cd "/Users/Negorashi2011/Dropbox/Working_docs/Luo_Mingjie_Oregon/HJA_scripts/5_taxonomy"

timestamp="20200214"
echo $timestamp
head kelpie_${timestamp}_BF3BR2_derep_filtered_geneious.fas
vsearch --cluster_size kelpie_${timestamp}_BF3BR2_derep_filtered_geneious.fas --sizein --sizeout --id 0.97 --sizeorder --centroids kelpie_${timestamp}_BF3BR2_derep_filtered_geneious_vsearch97.fas --uc kelpie_${timestamp}_BF3BR2_derep_filtered_geneious_vsearch97clusters.uc

seqkit stats kelpie_${timestamp}_BF3BR2_derep_filtered_geneious_vsearch97.fas
# 1,246 OTUs, min 403, avg 417.9, max 437

vsearch --sortbysize kelpie_${timestamp}_BF3BR2_derep_filtered_geneious_vsearch97.fas --minsize 2 --output kelpie_${timestamp}_BF3BR2_derep_filtered_geneious_vsearch97_min2.fas

seqkit stats kelpie_${timestamp}_BF3BR2_derep_filtered_geneious_vsearch97_min2.fas
# 1,211 OTUs, min 403, avg 417.9, max 437


# 96%
vsearch --cluster_size kelpie_${timestamp}_BF3BR2_derep_filtered_geneious.fas --sizein --sizeout --id 0.96 --sizeorder --centroids kelpie_${timestamp}_BF3BR2_derep_filtered_geneious_vsearch96.fas --uc kelpie_${timestamp}_BF3BR2_derep_filtered_geneious_vsearch96clusters.uc

seqkit stats kelpie_${timestamp}_BF3BR2_derep_filtered_geneious_vsearch96.fas
# 1,171 OTUs, min 403, avg 417.9, max 437

vsearch --sortbysize kelpie_${timestamp}_BF3BR2_derep_filtered_geneious_vsearch96.fas --minsize 2 --output kelpie_${timestamp}_BF3BR2_derep_filtered_geneious_vsearch96_min2.fas
seqkit stats kelpie_${timestamp}_BF3BR2_derep_filtered_geneious_vsearch96_min2.fas
# 1,149 OTUs, min 403, avg 417.9, max 437
```

Read in kelpie_${timestamp}_BF3BR2_derep_filtered_geneious_vsearch97_min2.fas and the two COI spike sequences from 8_reference_sequences/assembled_plasmids.fasta. Add together
```{r}
timestamp <- 20200214
kelpieotusclustered <- paste0("kelpie_", timestamp, "_BF3BR2_derep_filtered_geneious_vsearch97_min2.fas") 

# read in otu fasta
kelpie_otus <- read.fasta(file = file.path(kelpieotusclustered), seqtype = "DNA", as.string = TRUE, forceDNAtolower = FALSE, set.attributes = FALSE, strip.desc = TRUE, whole.header = TRUE)

# use unlist() %>% enframe() to convert list to dataframe 
kelpie_otusdf <- kelpie_otus %>% 
  unlist(recursive = FALSE) %>% 
  enframe(name = "name", value = "seq") 


# coispikefasta <- "COI_spike_sequences_3spp_BF3BR2.fas"
coispikefasta <- "assembled_plasmids.fasta"

# read in spikes fasta file (output is a list)
coispikes <- read.fasta(file = file.path("..", "8_reference_sequences_datasets", coispikefasta), seqtype = "DNA", as.string = TRUE, forceDNAtolower = FALSE, set.attributes = FALSE, strip.desc = TRUE, whole.header = TRUE)

# use unlist() %>% enframe() to convert list to dataframe 
coispikesdf <- coispikes %>% 
  unlist(recursive = FALSE) %>% 
  enframe(name = "name", value = "seq") 


# bind_rows to combine kelpie otus and spike seqs
kelpie_otus_and_spikes <- bind_rows(coispikesdf, kelpie_otusdf)

# write to working directory
writeFasta(kelpie_otus_and_spikes, paste0("kelpie_", timestamp, "_BF3BR2_derep_filtered_geneious_vsearch97_min2_spikes.fas"))
```

NEXT STEP
Use kelpie_20200214_BF3BR2_derep_filtered_geneious_vsearch97_min2_spikes.fas as the mapping target

# END




Below is archived code that used seqtk to generate the Geneious-filtered fasta file. Deprecated

seqtk subseq list 
```{r}
gbifdf_seqtk_subseq <- gbifdf %>% 
    select(occurrenceId)
# write_csv(gbifdf, "kelpie_20200214_BF3BR2_derep_filtered.csv")
# write_tsv(gbifdf_seqtk_subseq, "5_taxonomy/gbifdf_seqtk_subseq.tsv", col_names = FALSE)
```


# bash commands
Create filtered OTU fasta file
keyboard shortcut to send to terminal is opt-cmd-fn-return
```{bash cleanup}
cd ~/Dropbox/Working_docs/Luo_Mingjie_Oregon/HJA_scripts/5_taxonomy

# filter fasta
seqtk subseq kelpie_20200214_BF3BR2_derep.fas gbifdf_seqtk_subseq.tsv > kelpie_20200214_BF3BR2_derep_filtered.fas

seqkit stats kelpie_20200214_BF3BR2_derep_filtered.fas

# cleanup
rm gbifdf_seqtk_subseq.tsv
rm kelpie_20200214_BF3BR2_derep_filtered.csv
```

seqtk subseq list
```{r}

gbifdf_seqtk_subseq <- gbifdf %>% 
    select(occurrenceId)

write_csv(gbifdf, "5_taxonomy/kelpie_20200214_BF3BR2_derep_filtered_geneious.csv")

write_tsv(gbifdf_seqtk_subseq, "5_taxonomy/gbifdf_seqtk_subseq_geneious.tsv", col_names = FALSE)
```

Create filtered OTU fasta file
keyboard shortcut to send to terminal is opt-cmd-fn-return
```{bash cleanup}
cd ~/Dropbox/Working_docs/Luo_Mingjie_Oregon/HJA_scripts/5_taxonomy

# filter fasta
seqkit stats kelpie_20200214_BF3BR2_derep_filtered.fas

seqtk subseq kelpie_20200214_BF3BR2_derep_filtered.fas gbifdf_seqtk_subseq_geneious.tsv > kelpie_20200214_BF3BR2_derep_filtered_geneious.fas

seqkit stats kelpie_20200214_BF3BR2_derep_filtered_geneious.fas

# cleanup
rm gbifdf_seqtk_subseq_geneious.tsv
```


Archived code

```{r}
gbifdfoutput <- "kelpie_20200214_BF3BR2_derep_filtered"

# write_csv(gbifdf, paste0("kelpie_20200214_BF3BR2_derep_filtered", ".csv"))
# gbifdf <- read_csv("kelpie_20200214_BF3BR2_derep_filtered.csv")
```

View kelpie_20200214_BF3BR2_derep_filtered.csv file in Excel

Create a fasta file of the filtered gbifdf file
```{r}
kelpie_otus <- select(gbifdf, name = occurrenceId, seq = sequence)

# write to working directory
# writeFasta(kelpie_otus, paste0("kelpie_20200214_BF3BR2_derep_filtered", ".fas"))
```

kelpie_20200214_BF3BR2_derep_filtered.fas # 1,166 sequences


